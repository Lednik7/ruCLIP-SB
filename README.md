# ruCLIP-SB
RuCLIP-SB (Russian Contrastive Languageâ€“Image Pretraining SWIN-BERT) is a multimodal model for obtaining images and text similarities and rearranging captions and pictures. Unlike other versions of the model we use BERT for text encoder and SWIN transformer for image encoder. 

##Our model achieved 37.02% zero-shot accuracy on CIFAR100. 
We train model on 2 million images on Google Colab.


![image](https://github.com/cene555/ruCLIP-SB/blob/main/pictures/Similarity.png)



