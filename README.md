# ruCLIP-SB
RuCLIP-SB (Russian Contrastive Languageâ€“Image Pretraining SWIN-BERT) is a multimodal model for obtaining images and text similarities and rearranging captions and pictures. Unlike other versions of the model we use BERT for text encoder and SWIN transformer for image encoder. 

## Our model achieved 37.02% zero-shot accuracy on CIFAR100 and have 39543907 parametres. 
We train model on 2 million images on Google Colab.
[ruCLIP-SB](https://www.google.com)

![image](https://github.com/cene555/ruCLIP-SB/blob/main/pictures/Similarity.png)


### Thanks to Sber AI for help.
